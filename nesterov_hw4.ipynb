{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 13 июня 2022, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 13 июня, -4 балла после 08:30 20 июня, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0422, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(z, y_i) = (y_i - z) ^ 2,~\\frac{\\partial L}{\\partial z} = -2(y_i - z),~\\left.-\\frac{\\partial L}{\\partial z}\\right\\vert_{\\large z=F_{k-1}(x_i)}=2(y_i - F_{k-1}(x_i))$$\n",
    "\n",
    "$$L(z, y_i) = e^{\\large -zy_i},~\\frac{\\partial L}{\\partial z}=-y_ie^{\\large -zy_i},~\\left.-\\frac{\\partial L}{\\partial z}\\right\\vert_{\\large z=F_{k-1}(x_i)}=y_ie^{\\large -y_iF_{k-1}(x_i)}$$\n",
    "\n",
    "$$L(z, y_i) = \\log(1 + e^{\\large -zy_i}),~\\frac{\\partial L}{\\partial z}=-y_i\\frac{e^{\\large -zy_i}}{1 + e^{\\large -zy_i}},~\\left.-\\frac{\\partial L}{\\partial z}\\right\\vert_{\\large z=F_{k-1}(x_i)}=y_i\\frac{e^{\\large -y_iF_{k-1}(x_i)}}{1 + e^{\\large -y_iF_{k-1}(x_i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# for results reproducing\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss: str = 'mse', learning_rate: float = 0.1, n_estimators: int = 100, \n",
    "        colsample: float = 1.0, subsample: float = 1.0,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов: 'mse', 'exp', 'log'\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучении одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучении одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        if loss not in ['mse', 'exp', 'log']:\n",
    "            raise ValueError(f\"Bad loss: {loss}\")\n",
    "\n",
    "        self.base_model_args = args\n",
    "        self.base_model_kwargs = kwargs\n",
    "        \n",
    "        self.loss = loss\n",
    "        self.lr = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        \n",
    "        self.models = []\n",
    "        self.gammas = []\n",
    "    \n",
    "    def _bootstrap_idx(self, train: np.ndarray):\n",
    "        n_objects, n_features = train.shape\n",
    "        samples_idx = np.random.permutation(n_objects)[:int(self.subsample * n_objects)]\n",
    "        features_idx = np.random.permutation(n_features)[:int(self.colsample * n_features)]\n",
    "        return samples_idx, features_idx\n",
    "    \n",
    "    def _find_optimal_gamma(self, y: np.array, old_predictions: np.array, new_predictions: np.array) -> float:\n",
    "        \"\"\"\n",
    "        y -- таргеты для обучения\n",
    "        \"\"\"\n",
    "        def min_func(gamma):\n",
    "            if self.loss == 'mse':\n",
    "                return ((y - (old_predictions + gamma * new_predictions)) ** 2).mean()\n",
    "            elif self.loss == 'exp':\n",
    "                return np.exp(-(old_predictions + gamma * new_predictions) * y).mean()\n",
    "            elif self.loss == 'log':\n",
    "                return np.log(1 + np.exp(-(old_predictions + gamma * new_predictions) * y)).mean()\n",
    "        \n",
    "        return minimize(min_func, x0=0.5).x\n",
    "    \n",
    "    def _fit_base_model(self, x: np.ndarray, y: np.array, base_model_cls: Callable):\n",
    "        \"\"\"\n",
    "        x -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        \"\"\"\n",
    "        base_model = base_model_cls(*self.base_model_args, **self.base_model_kwargs)\n",
    "        base_model.fit(x, y)\n",
    "        return base_model\n",
    "    \n",
    "    def _rescale(self, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        scale target to [-1, 1]\n",
    "        \"\"\"\n",
    "        return (self.min + self.max - 2 * y) / (self.min - self.max)\n",
    "    \n",
    "    def _rescale_back(self, predicts: np.ndarray):\n",
    "        pred_min, pred_max = np.min(predicts), np.max(predicts)\n",
    "        k = (self.min - self.max) / (pred_min - pred_max)\n",
    "        b = (self.max * pred_min - self.min * pred_max) / (pred_min - pred_max)\n",
    "        return k * predicts + b\n",
    "    \n",
    "    def fit(self, x_src, y_src, base_model_cls=DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        x -- объекты для обучения\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        x = x_src.copy()\n",
    "        \n",
    "        self.min = np.min(y_src)\n",
    "        self.max = np.max(y_src)\n",
    "        y = self._rescale(y_src)\n",
    "        \n",
    "        base_model = DummyRegressor() if init_model is None else init_model\n",
    "        base_model.fit(x, y)\n",
    "        base_model.features_idx = np.arange(x.shape[1])\n",
    "        self.models.append(base_model)\n",
    "        self.gammas.append(1.0)\n",
    "\n",
    "        for i in range(1, self.n_estimators):\n",
    "            old_preds = self._predict(x)\n",
    "            \n",
    "            new_targets = None\n",
    "            if self.loss == 'mse':\n",
    "                new_targets = 2 * (y - old_preds)\n",
    "            elif self.loss == 'exp':\n",
    "                new_targets = y * np.exp(-old_preds * y)\n",
    "            elif self.loss == 'log':\n",
    "                exp = np.exp(-old_preds * y)\n",
    "                new_targets = y * exp / (1 + exp)\n",
    "            \n",
    "            samples_idx, features_idx = self._bootstrap_idx(x)\n",
    "\n",
    "            base_model = self._fit_base_model(\n",
    "                x[samples_idx, :][:, features_idx],\n",
    "                new_targets[samples_idx], \n",
    "                base_model_cls\n",
    "            )\n",
    "            base_model.features_idx = features_idx\n",
    "            \n",
    "            gamma = self._find_optimal_gamma(y, old_preds, base_model.predict(x[:, features_idx]))\n",
    "\n",
    "            self.models.append(base_model)\n",
    "            self.gammas.append(gamma)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        predicts = np.zeros((x.shape[0]))\n",
    "        for gamma, base_model in zip(self.gammas, self.models):\n",
    "            predicts += self.lr * gamma * base_model.predict(x[:, base_model.features_idx])\n",
    "        return predicts\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.round(self._rescale_back(self._predict(x))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier(max_depth=3)\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wine.data, wine.target,\n",
    "    test_size=0.1,\n",
    "    stratify=wine.target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовать разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy: 0.8265503875968992\n"
     ]
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"initial accuracy: {accuracy_score(y_pred=clf.predict(X_val), y_true=y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Точность в зависимости от числа итераций на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [04:09<00:00, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "estimators = range(10, 160, 10)\n",
    "estimators_scores = []\n",
    "for n_estimators in tqdm(estimators):\n",
    "    clf = MyGradientBoostingClassifier(n_estimators=n_estimators)\n",
    "    clf.fit(X_train, y_train)\n",
    "    estimators_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_n_estimators = estimators[np.argmax(estimators_scores)]\n",
    "print(f\"Best n_estimators: {best_n_estimators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy on val\")\n",
    "plt.title(\"Зависимость точности от количества итераций\")\n",
    "plt.plot(estimators, estimators_scores)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор оптимальных параметров на валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [01:01<00:00, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = ['mse', 'exp', 'log']\n",
    "losses_scores = []\n",
    "for loss in tqdm(losses):\n",
    "    clf = MyGradientBoostingClassifier(loss=loss)\n",
    "    clf.fit(X_train, y_train)\n",
    "    losses_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_loss = losses[np.argmax(losses_scores)]\n",
    "print(f\"Best loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [01:11<00:00, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lrs = np.arange(0.1, 0.6, 0.1)\n",
    "lr_scores = []\n",
    "for lr in tqdm(lrs):\n",
    "    clf = MyGradientBoostingClassifier(learning_rate=lr)\n",
    "    clf.fit(X_train, y_train)\n",
    "    lr_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_lr = lrs[np.argmax(lr_scores)]\n",
    "print(f\"Best learning rate: {best_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [02:23<00:00, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best colsample: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "colsamples = np.linspace(1/8, 1.0, 8)\n",
    "colsamples_scores = []\n",
    "for colsample in tqdm(colsamples):\n",
    "    clf = MyGradientBoostingClassifier(colsample=colsample)\n",
    "    clf.fit(X_train, y_train)\n",
    "    colsamples_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_colsample = colsamples[np.argmax(colsamples_scores)]\n",
    "print(f\"Best colsample: {best_colsample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [03:53<00:00, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subsample: 0.39999999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subsamples = np.linspace(0.3, 1.0, 8)\n",
    "subsamples_scores = []\n",
    "for subsample in tqdm(subsamples):\n",
    "    clf = MyGradientBoostingClassifier(subsample=subsample)\n",
    "    clf.fit(X_train, y_train)\n",
    "    subsamples_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_subsample = subsamples[np.argmax(subsamples_scores)]\n",
    "print(f\"Best subsample: {best_subsample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [01:06<00:00,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_depths = range(3, 10)\n",
    "max_depths_scores = []\n",
    "for max_depth in tqdm(max_depths):\n",
    "    clf = MyGradientBoostingClassifier(max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    max_depths_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "best_max_depth = max_depths[np.argmax(max_depths_scores)]\n",
    "print(f\"Best max depth: {best_max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Качество на подобранных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50,\n",
       " 'loss': 'log',\n",
       " 'learning_rate': 0.2,\n",
       " 'colsample': 0.75,\n",
       " 'subsample': 0.39999999999999997,\n",
       " 'max_depth': 7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {\n",
    "    \"n_estimators\": best_n_estimators,\n",
    "    \"loss\": best_loss,\n",
    "    \"learning_rate\": best_lr,\n",
    "    \"colsample\": best_colsample,\n",
    "    \"subsample\": best_subsample,\n",
    "    \"max_depth\": best_max_depth\n",
    "}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8888081395348837\n"
     ]
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(**best_params)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"accuracy: {accuracy_score(y_pred=clf.predict(X_val), y_true=y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэггинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8817829457364341\n"
     ]
    }
   ],
   "source": [
    "# RandomForest as base model\n",
    "\n",
    "clf = MyGradientBoostingClassifier(n_estimators=10)\n",
    "clf.fit(X_train, y_train, base_model_cls=RandomForestRegressor)\n",
    "print(f\"accuracy: {accuracy_score(y_pred=clf.predict(X_val), y_true=y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8684593023255814\n"
     ]
    }
   ],
   "source": [
    "# Bagging on gradient boosting machines\n",
    "\n",
    "n_classifiers = 10\n",
    "classifiers = [MyGradientBoostingClassifier() for _ in range(n_classifiers)]\n",
    "for clf in classifiers:\n",
    "    samples_idx = np.random.permutation(X_train.shape[0])[:X_train.shape[0] // 2]\n",
    "    clf.fit(X_train[samples_idx, :], y_train[samples_idx])\n",
    "\n",
    "prediction = np.zeros(X_val.shape[0])\n",
    "for clf in classifiers:\n",
    "    prediction += clf.predict(X_val)\n",
    "prediction /= len(classifiers)\n",
    "prediction = np.round(prediction)\n",
    "\n",
    "print(f\"accuracy: {accuracy_score(y_pred=prediction, y_true=y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае бустинга над случайными лесами качество увеличилось засчет того, что первый обученный случайный лес уже выдавал предсказание сильно лучше, чем одно единственное дерево решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.877422480620155\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "print(f\"accuracy: {accuracy_score(y_pred=np.round(reg.predict(X_val)), y_true=y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае же бэггинга над бустингами, срабатывает идея бэггинга: ансамблирование большого числа слабых моделей увеличивает качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:10<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best init model: RandomForestRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestRegressor(), SGDRegressor()]\n",
    "models_names = [\"RandomForest\", \"Linear regression\"]\n",
    "models_scores = []\n",
    "for model in tqdm(models):\n",
    "    clf = MyGradientBoostingClassifier(n_estimators=10)\n",
    "    clf.fit(X_train, y_train, init_model=model)\n",
    "    models_scores.append(accuracy_score(y_pred=clf.predict(X_val), y_true=y_val))\n",
    "\n",
    "print(f\"Best init model: {models[np.argmax(models_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.823886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear regression</td>\n",
       "      <td>0.577762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              models    scores\n",
       "0       RandomForest  0.823886\n",
       "1  Linear regression  0.577762"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"models\": models_names, \"scores\": models_scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, качество увеличилось при использовании сильной начальной модели (случайный лес), при использовании же неподходящей для задачи модели (линейной), наблюдается уменьшение точности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
